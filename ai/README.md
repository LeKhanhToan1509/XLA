# LeNet-5 Implementation - MNIST + Shapes Classification

## ğŸ“‹ Tá»•ng quan

Implement **LeNet-5 CNN tá»« Ä‘áº§u** (from scratch) vá»›i **NumPy thuáº§n** (khÃ´ng dÃ¹ng TensorFlow, PyTorch hay báº¥t ká»³ deep learning framework nÃ o) Ä‘á»ƒ phÃ¢n loáº¡i 13 classes:
- **10 classes digits**: Chá»¯ sá»‘ 0-9 tá»« MNIST dataset
- **3 classes shapes**: HÃ¬nh trÃ²n (circle), vuÃ´ng (square), tam giÃ¡c (triangle) - tá»± generate

### âœ¨ Äáº·c Ä‘iá»ƒm ná»•i báº­t

- âœ… **100% From-scratch**: Chá»‰ dÃ¹ng NumPy, implement táº¥t cáº£ operations (conv, pooling, backprop)
- âœ… **SDLM Optimizer**: Stochastic Diagonal Levenberg-Marquardt cho adaptive learning rate
- âœ… **RBF Output Layer**: Radial Basis Function vá»›i bitmap patterns (7Ã—12 ASCII-style)
- âœ… **C3 Layer Mapping**: Theo paper gá»‘c cá»§a LeCun (khÃ´ng pháº£i full connection)
- âœ… **Flexible Architecture**: Há»— trá»£ 10 classes (MNIST) hoáº·c 13 classes (MNIST+shapes)
- âœ… **Model Checkpointing**: Auto-save weights má»—i epoch Ä‘á»ƒ tiáº¿p tá»¥c training hoáº·c analyze

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
ai/
â”œâ”€â”€ main.py                 # Entry point - cháº¡y toÃ n bá»™ pipeline
â”œâ”€â”€ train_lenet.py          # Training module vá»›i Ä‘áº§y Ä‘á»§ functions
â”œâ”€â”€ README.md               # File nÃ y
â”œâ”€â”€ requirements.txt        # Dependencies (numpy, opencv-python, pillow, pickle)
â”œâ”€â”€ models/                 # Model checkpoints (auto-created)
â”‚   â”œâ”€â”€ model_weights_0.pkl     # Checkpoint epoch 0
â”‚   â”œâ”€â”€ model_weights_1.pkl     # Checkpoint epoch 1
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ model_weights_final.pkl # Best model
â””â”€â”€ utils/                  # Core implementation
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ LayerObjects.py         # LeNet-5 class + All layers
    â”œâ”€â”€ Convolution_util.py     # Conv forward/backward/SDLM
    â”œâ”€â”€ Pooling_util.py         # Pooling forward/backward
    â”œâ”€â”€ Activation_util.py      # LeNet5_squash activation
    â”œâ”€â”€ RBF_initial_weight.py   # Bitmap patterns (10 digits + 3 shapes)
    â”œâ”€â”€ utils_func.py           # Data loading, normalization, mini-batch
    â””â”€â”€ generate_shape.py       # Generate synthetic shape images

data/                       # Dataset (khÃ´ng trong repo)
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 0/, 1/, ..., 9/        # MNIST digits
â”‚   â”œâ”€â”€ circle/                # Generated circles
â”‚   â”œâ”€â”€ square/                # Generated squares
â”‚   â””â”€â”€ triangle/              # Generated triangles
â”œâ”€â”€ test/
â”‚   â””â”€â”€ (same structure)
â””â”€â”€ val/
    â””â”€â”€ (same structure)
```

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### BÆ°á»›c 0: Chuáº©n bá»‹ mÃ´i trÆ°á»ng

**YÃªu cáº§u**: Python 3.6+ (tested vá»›i Python 3.6 trÃªn Windows 10)

```bash
# CÃ i Ä‘áº·t dependencies
pip install numpy opencv-python pillow

# Hoáº·c dÃ¹ng requirements.txt
pip install -r ai/requirements.txt
```

### BÆ°á»›c 1: Chuáº©n bá»‹ dataset

#### Option A: DÃ¹ng MNIST digits only (10 classes)

Download MNIST tá»« [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/) hoáº·c dÃ¹ng `MNIST_auto_Download.py`.

Cáº¥u trÃºc thÆ° má»¥c:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 0/ (áº£nh sá»‘ 0)
â”‚   â”œâ”€â”€ 1/ (áº£nh sá»‘ 1)
â”‚   â””â”€â”€ ...
â””â”€â”€ test/
    â””â”€â”€ (same structure)
```

#### Option B: MNIST + Shapes (13 classes) - **Recommended**

**1.1. Generate shape dataset**

```bash
cd e:\PTIT\XLA
python ai\utils\generate_shape.py
```

Sáº½ táº¡o:
- **train**: 800 images/class (circle, square, triangle)
- **val**: 100 images/class
- **test**: 100 images/class

Má»—i áº£nh:
- Size: 28Ã—28 grayscale
- Format: PNG
- Features: Centered shapes, clean background, high contrast

**1.2. Combine vá»›i MNIST**

Äáº·t MNIST digits vÃ o cÃ¹ng thÆ° má»¥c `data/train/` vÃ  `data/test/`. Káº¿t quáº£:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ 0/, 1/, ..., 9/    â† MNIST digits (10 classes)
â”‚   â”œâ”€â”€ circle/            â† Generated shapes (3 classes)
â”‚   â”œâ”€â”€ square/
â”‚   â””â”€â”€ triangle/
â””â”€â”€ test/
    â””â”€â”€ (same structure)
```

### BÆ°á»›c 2: Train model

**CÃ¡ch 1: DÃ¹ng main.py (recommended)**

```bash
cd e:\PTIT\XLA
python ai\main.py
```

**CÃ¡ch 2: Train trá»±c tiáº¿p**

```bash
cd e:\PTIT\XLA
python ai\train_lenet.py
```

**CÃ¡ch 3: DÃ¹ng Jupyter Notebook**

Má»Ÿ `LeNet-from-Scratch/LeNet5_train.ipynb` vÃ  cháº¡y tá»«ng cell.

### BÆ°á»›c 3: Customize hyperparameters

Sá»­a trong `ai/main.py` hoáº·c `ai/train_lenet.py`:

```python
model = train_lenet5(
    # Dataset paths
    train_folder=r'E:\PTIT\XLA\data\train',
    test_folder=r'E:\PTIT\XLA\data\test',
    
    # Model config
    n_classes=13,               # 10: MNIST only, 13: MNIST+shapes
    
    # Training config
    num_epochs=20,              # Sá»‘ epochs (paper gá»‘c dÃ¹ng 20)
    mini_batch_size=256,        # Batch size (paper khÃ´ng nÃ³i rÃµ, máº·c Ä‘á»‹nh 256)
    
    # Optimizer config (SDLM)
    lr_global=5e-3,             # Global learning rate (paper: 5e-4, nhÆ°ng dÃ¹ng 5e-3 há»™i tá»¥ nhanh hÆ¡n)
    momentum=0.9,               # Momentum SGD (khÃ´ng cÃ³ trong paper gá»‘c)
    weight_decay=0,             # L2 regularization (paper gá»‘c khÃ´ng dÃ¹ng)
    mu=0.01,                    # SDLM diagonal offset parameter
    
    # Checkpoint config
    save_dir='ai/models',       # ThÆ° má»¥c lÆ°u checkpoints
    save_interval=1             # Save má»—i N epochs (1 = save má»i epoch)
)
```

**âš ï¸ LÆ°u Ã½ quan trá»ng:**
- `lr_global`: Paper gá»‘c dÃ¹ng `5e-4` Ä‘áº¿n `1e-5`, nhÆ°ng implement nÃ y cáº§n `5e-3` (Ã—100) do cÃ³ thá»ƒ cÃ³ khÃ¡c biá»‡t trong SDLM implementation
- `momentum=0.9`: KhÃ´ng cÃ³ trong paper gá»‘c nhÆ°ng giÃºp há»™i tá»¥ nhanh hÆ¡n
- `n_classes`: **Báº®T BUá»˜C** set Ä‘Ãºng sá»‘ classes trong dataset

## ğŸ—ï¸ Kiáº¿n trÃºc LeNet-5

```
Input (32Ã—32Ã—1)
    â†“
C1: Conv 5Ã—5, 6 filters â†’ (28Ã—28Ã—6)
    â†“
S2: AvgPool 2Ã—2 â†’ (14Ã—14Ã—6)
    â†“
C3: Conv 5Ã—5, 16 filters (with mapping) â†’ (10Ã—10Ã—16)
    â†“
S4: AvgPool 2Ã—2 â†’ (5Ã—5Ã—16)
    â†“
C5: Conv 5Ã—5, 120 filters â†’ (1Ã—1Ã—120)
    â†“
F6: Fully Connected â†’ (84)
    â†“
RBF: Output layer â†’ (13 classes)
```

## ğŸ“Š Features

- âœ… **From-scratch implementation**: NumPy only, khÃ´ng dÃ¹ng deep learning framework
- âœ… **SDLM optimizer**: Stochastic Diagonal Levenberg-Marquardt cho adaptive learning rate
- âœ… **RBF layer**: Radial Basis Function vá»›i bitmap patterns
- âœ… **Data augmentation**: Light noise cho shapes
- âœ… **Model checkpointing**: LÆ°u weights má»—i epoch
- âœ… **Clean code**: Modular, dá»… hiá»ƒu vÃ  má»Ÿ rá»™ng

## ğŸ“ˆ QuÃ¡ trÃ¬nh training

### Console output máº«u

```
======================================================================
                   LeNet-5 Training Pipeline
======================================================================

Starting LeNet-5 training...
======================================================================
LeNet-5 Training - MNIST + Shapes Classification
======================================================================

[1/5] Loading dataset...
Class mapping: {'0': 0, '1': 1, '2': 2, ..., 'circle': 10, 'square': 11, 'triangle': 12}
Loaded 113925 images from E:\PTIT\XLA\data\train
Loaded 14380 images from E:\PTIT\XLA\data\test

âœ“ Dataset Info:
  - Training samples: 113925
  - Test samples: 14380
  - Image shape: (28, 28)
  - Unique labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12]
  - Number of classes: 13

[2/5] Preprocessing images...
âœ“ After padding (pad=2):
  - Training shape: (113925, 32, 32, 1)
  - Test shape: (14380, 32, 32, 1)

[3/5] Initializing LeNet-5 model...
âœ“ Model architecture:
  C1 (Conv 5x5x1x6) â†’ S2 (AvgPool 2x2) â†’ C3 (Conv 5x5x6x16) â†’
  S4 (AvgPool 2x2) â†’ C5 (Conv 5x5x16x120) â†’ F6 (FC 120â†’84) â†’
  RBF (Output 13 classes)

[4/5] Training model...
Hyperparameters:
  - Epochs: 20
  - Batch size: 256
  - Global LR: 0.005
  - Momentum: 0.9
  - Weight decay: 0
  - SDLM mu: 0.01
----------------------------------------------------------------------
Epoch 1/20 - Loss: 0.5234 - Test Acc: 85.32% - Time: 123.4s
  â†’ Model saved: ai/models/model_weights_0.pkl
Epoch 2/20 - Loss: 0.3421 - Test Acc: 91.45% - Time: 118.2s
  â†’ Model saved: ai/models/model_weights_1.pkl
...
Epoch 20/20 - Loss: 0.0512 - Test Acc: 97.82% - Time: 115.8s
  â†’ Model saved: ai/models/model_weights_19.pkl

[5/5] Final evaluation...

======================================================================
Training Complete!
======================================================================
Final Train Accuracy: 98.91%
Final Test Accuracy: 97.82%

Best Test Accuracy: 98.05% (Epoch 18)

Final model saved: ai/models/model_weights_final.pkl

âœ… Training complete! Model checkpoints saved in ai/models/
```

### Thá»i gian training Æ°á»›c tÃ­nh

- **1 epoch**: ~2-3 phÃºt (CPU), ~30-60s (GPU - náº¿u cÃ³ optimize cho GPU)
- **20 epochs**: ~40-60 phÃºt (CPU)
- Phá»¥ thuá»™c vÃ o:
  - CPU/GPU
  - Batch size
  - Sá»‘ lÆ°á»£ng training samples

## ğŸ”§ Load vÃ  test trained model

### CÃ¡ch 1: DÃ¹ng Python script

```python
import numpy as np
from ai.train_lenet import load_model, evaluate_model
from ai.utils.utils_func import readDatasetFromFolder, zero_pad, normalize

# Load model checkpoint
model = load_model('ai/models/model_weights_19.pkl', n_classes=13)

# Load test data
test_image, test_label = readDatasetFromFolder(r'E:\PTIT\XLA\data\test')
test_image_pad = normalize(zero_pad(test_image[:,:,:,np.newaxis], 2), 'lenet5')

# Evaluate toÃ n bá»™ test set
accuracy = evaluate_model(model, test_image_pad, test_label)
print(f"Test Accuracy: {accuracy:.2f}%")

# Predict má»™t áº£nh cá»¥ thá»ƒ
from PIL import Image

img = Image.open('path/to/image.png').convert('L')
img = img.resize((28, 28))
img_array = np.array(img)
img_input = normalize(zero_pad(img_array[np.newaxis, :, :, np.newaxis], 2), 'lenet5')

# Forward pass
_, prediction = model.Forward_Propagation(img_input, np.array([0]), mode='test')
print(f"Predicted class: {prediction[0]}")

# Mapping labels
class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'circle', 'square', 'triangle']
print(f"Predicted: {class_names[prediction[0]]}")
```

### CÃ¡ch 2: DÃ¹ng Jupyter Notebook

Má»Ÿ `LeNet-from-Scratch/a.ipynb` (notebook Ä‘Ã£ cÃ³ sáºµn Ä‘á»ƒ test model):

1. Load model weights tá»« checkpoint
2. Test vá»›i random images tá»« test set
3. Visualize feature maps cá»§a tá»«ng layer
4. Compare accuracy across epochs

### CÃ¡ch 3: Analyze model trong notebook

File `LeNet5_train.ipynb` cÃ³ Ä‘áº§y Ä‘á»§ visualization:
- Feature maps cá»§a C1, S2, C3, S4, C5, F6 layers
- Kernels/filters cá»§a conv layers
- RBF layer output
- Training curves (loss, accuracy)

## ğŸ“Š Káº¿t quáº£ ká»³ vá»ng

### Accuracy theo paper gá»‘c (MNIST 10 classes)
- **After 1st epoch**: ~93.5%
- **After 20 epochs**: ~98.6%
- **Best reported**: 99.05%

### Accuracy vá»›i implementation nÃ y (MNIST + Shapes 13 classes)

#### MNIST Digits (0-9):
- **After 1st epoch**: ~88-92%
- **After 20 epochs**: ~96-98%
- Digits thÆ°á»ng dá»… há»c hÆ¡n shapes do data cháº¥t lÆ°á»£ng cao

#### Shapes (circle, square, triangle):
- **Vá»›i old data generation** (noisy, off-center): ~30-70%
- **Vá»›i new data generation** (clean, centered): ~85-95%
- Key: Data quality ráº¥t quan trá»ng cho shapes

#### Overall (13 classes):
- **After 1st epoch**: ~85-90%
- **After 20 epochs**: ~93-97%
- **Best achievable**: ~97-98%

### Training curve patterns
- **Loss**: Giáº£m nhanh trong 5 epochs Ä‘áº§u, sau Ä‘Ã³ giáº£m cháº­m vÃ  á»•n Ä‘á»‹nh
- **Train accuracy**: TÄƒng nhanh, cÃ³ thá»ƒ Ä‘áº¡t >98% sau 10-15 epochs
- **Test accuracy**: TÄƒng cháº­m hÆ¡n train, gap nhá» (~1-2%) do model khÃ´ng quÃ¡ complex

## ğŸ“ Chi tiáº¿t ká»¹ thuáº­t

### Input preprocessing
1. **Original images**: 28Ã—28 grayscale (pixel values 0-255)
2. **Zero-padding**: pad=2 â†’ 32Ã—32 (Ä‘á»ƒ C1 output 28Ã—28)
3. **Normalization**: Pixel values â†’ [-0.1, 1.175]
   - Formula: `(pixel / 255) * 1.275 - 0.1`
   - Mean â‰ˆ 0 (theo paper gá»‘c)

### C3 layer mapping (16 feature maps)
KhÃ´ng pháº£i full connection 6â†’16, mÃ  theo table trong paper:
```
Maps 0-5:   Connect to 3 input maps (6 combinations)
Maps 6-11:  Connect to 4 input maps (6 combinations)
Maps 12-14: Connect to 4 discontinuous maps (3 combinations)
Map 15:     Connect to all 6 input maps (1 full connection)
```

LÃ½ do: Giáº£m sá»‘ parameters, tÄƒng diversity cá»§a features

### RBF output layer
- **10 digit patterns**: Bitmap 7Ã—12 (84 features) theo ASCII art
- **3 shape patterns**: Bitmap 7Ã—12 tÆ°Æ¡ng tá»± (circle, square, triangle)
- **Loss function**: Euclidean distance giá»¯a F6 output vÃ  bitmap pattern
- KhÃ´ng trainable (fixed weights)

### Shapes generation specs
- **Size**: 28Ã—28 pixels
- **Position**: Centered at (14, 14)
- **Circle radius**: 6-10 pixels
- **Square side**: 12-20 pixels (Â±6-10 from center)
- **Triangle**: Equilateral, vertex pointing up, size 6-10 pixels
- **Background**: Uniform gray (20-80)
- **Foreground**: White-ish (200-255)
- **Augmentation**: Light Gaussian noise (Ïƒ=5) on 30% images

### Optimizer: SDLM (Stochastic Diagonal Levenberg-Marquardt)
- **Purpose**: Adaptive learning rate per layer
- **Formula**: `lr = lr_global / (mu + h)`
  - `h`: Approximate diagonal Hessian (tá»« second derivative)
  - `mu`: Offset parameter (0.01-0.02)
- **Benefits**: Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh learning rate dá»±a trÃªn curvature
- **Paper note**: Implementation nÃ y scale lr_global Ã—100 so vá»›i paper gá»‘c

## ğŸ› Troubleshooting

### Import errors

**Lá»—i**: `ModuleNotFoundError: No module named 'ai'` hoáº·c `No module named 'utils'`

**NguyÃªn nhÃ¢n**: Cháº¡y script tá»« sai directory

**Giáº£i phÃ¡p**:
```bash
# ÄÃšNG: Cháº¡y tá»« root directory
cd e:\PTIT\XLA
python ai\main.py

# SAI: Cháº¡y tá»« bÃªn trong ai/
cd e:\PTIT\XLA\ai
python main.py  # â† Sáº½ lá»—i import
```

### Low shapes accuracy

**Triá»‡u chá»©ng**: Shapes accuracy <70% sau 10+ epochs, hoáº·c model predict táº¥t cáº£ shapes lÃ  1 class

**NguyÃªn nhÃ¢n**: 
1. Data generation cÅ© táº¡o shapes off-center, noisy, size khÃ´ng consistent
2. RBF bitmap patterns khÃ´ng match vá»›i data

**Giáº£i phÃ¡p**:
1. **Regenerate data** vá»›i `generate_shape.py` má»›i:
   ```bash
   python ai\utils\generate_shape.py
   ```
2. **Check RBF patterns**: File `ai/utils/RBF_initial_weight.py` pháº£i cÃ³ `bitmap_circle`, `bitmap_square`, `bitmap_triangle`
3. **Retrain tá»« Ä‘áº§u**: XÃ³a old checkpoints vÃ  train láº¡i vá»›i data má»›i

### Memory errors

**Lá»—i**: `MemoryError` hoáº·c `numpy.core._exceptions._ArrayMemoryError`

**NguyÃªn nhÃ¢n**: Batch size quÃ¡ lá»›n cho RAM

**Giáº£i phÃ¡p**:
```python
# Giáº£m batch size
model = train_lenet5(
    mini_batch_size=128,  # Thay vÃ¬ 256
    # hoáº·c
    mini_batch_size=64    # Cho RAM <8GB
)
```

### Training quÃ¡ cháº­m

**Triá»‡u chá»©ng**: 1 epoch >5 phÃºt

**NguyÃªn nhÃ¢n**: 
1. Cháº¡y trÃªn CPU thuáº§n
2. Code NumPy khÃ´ng optimize
3. Dataset quÃ¡ lá»›n

**Giáº£i phÃ¡p**:
1. **Reduce dataset**: Test vá»›i subset nhá» trÆ°á»›c
   ```python
   # Trong train_lenet.py, sau khi load data:
   train_image = train_image[:10000]  # Chá»‰ láº¥y 10k samples
   train_label = train_label[:10000]
   ```
2. **TÄƒng batch size**: Náº¿u RAM Ä‘á»§, tÄƒng lÃªn 512
3. **Giáº£m epochs**: Test vá»›i 5-10 epochs trÆ°á»›c

### Accuracy khÃ´ng tÄƒng sau nhiá»u epochs

**Triá»‡u chá»©ng**: Accuracy plateau á»Ÿ ~70-80%, khÃ´ng cáº£i thiá»‡n

**NguyÃªn nhÃ¢n**:
1. Learning rate khÃ´ng phÃ¹ há»£p
2. Data imbalance (shapes Ã­t hÆ¡n digits ráº¥t nhiá»u)
3. Model Ä‘Ã£ overfit hoáº·c underfit

**Giáº£i phÃ¡p**:
1. **Adjust learning rate**:
   ```python
   # TÄƒng lr náº¿u loss giáº£m quÃ¡ cháº­m
   model = train_lenet5(lr_global=1e-2)  # Default: 5e-3
   
   # Giáº£m lr náº¿u loss dao Ä‘á»™ng máº¡nh
   model = train_lenet5(lr_global=1e-3)
   ```
2. **Check data balance**:
   ```python
   print(np.bincount(train_label))  # Count samples per class
   ```
3. **Visualize predictions**: DÃ¹ng notebook `a.ipynb` Ä‘á»ƒ xem model predict sai á»Ÿ Ä‘Ã¢u

### Model khÃ´ng save Ä‘Æ°á»£c

**Lá»—i**: `PicklingError` hoáº·c `AttributeError` khi save

**NguyÃªn nhÃ¢n**: Trying to pickle class definitions thay vÃ¬ weights

**Giáº£i phÃ¡p**: Code Ä‘Ã£ fix - chá»‰ save weights dict, khÃ´ng save class object. Náº¿u váº«n lá»—i:
```python
# Trong train_lenet.py, check model_state cÃ³ Ä‘Ãºng format:
model_state = {
    'C1_weight': ConvNet.C1.weight,  # NumPy array
    'C1_bias': ConvNet.C1.bias,      # NumPy array
    # ... (only numpy arrays, no objects)
}
```

### Shapes predict háº¿t lÃ  "square"

**Triá»‡u chá»©ng**: Circle vÃ  triangle Ä‘á»u Ä‘Æ°á»£c predict lÃ  square (label 11)

**NguyÃªn nhÃ¢n**: 
1. Data generation táº¡o shapes quÃ¡ giá»‘ng nhau
2. Model collapse do learning rate quÃ¡ cao hoáº·c quÃ¡ tháº¥p
3. RBF patterns khÃ´ng Ä‘á»§ distinctive

**Giáº£i phÃ¡p**:
1. **Kiá»ƒm tra data**:
   ```python
   import cv2
   import matplotlib.pyplot as plt
   
   # Load vÃ  visualize vÃ i áº£nh tá»« má»—i class
   for shape in ['circle', 'square', 'triangle']:
       img = cv2.imread(f'data/train/{shape}/{shape}_00000.png', 0)
       plt.imshow(img, cmap='gray')
       plt.title(shape)
       plt.show()
   ```
2. **Regenerate data** vá»›i parameters khÃ¡c:
   ```python
   # Trong generate_shape.py, tÄƒng diversity:
   radius = random.randint(8, 12)  # Thay vÃ¬ 6-10
   ```
3. **Check F6 features**: Xem cosine similarity giá»¯a classes trong `a.ipynb`

## ğŸ“š References

### Papers
- **[LeCun et al., 1998]** [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)
  - Original LeNet-5 paper
  - Architecture, SDLM optimizer, RBF layer details
  
- **[LeCun et al., 1989]** [Backpropagation Applied to Handwritten Zip Code Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf)
  - Early CNN architecture inspiration

### Datasets
- **MNIST**: [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/)
  - 60,000 training + 10,000 test images
  - 28Ã—28 grayscale handwritten digits

### Implementation Notes
- Code structure inspired by [Andrew Ng's Deep Learning Course](https://www.coursera.org/specializations/deep-learning)
- SDLM implementation details from original LeNet-5 paper
- RBF layer bitmap patterns designed theo ASCII art style trong paper

## ğŸ¤ Contributing

Náº¿u báº¡n muá»‘n cáº£i thiá»‡n code hoáº·c fix bugs:

1. **Tá»‘i Æ°u performance**: Vectorize operations trong Convolution_util.py
2. **ThÃªm augmentation**: Random rotation, shift cho shapes
3. **Support GPU**: Thá»­ integrate CuPy thay vÃ¬ NumPy
4. **Visualization**: ThÃªm TensorBoard hoáº·c Weights & Biases logging
5. **More datasets**: Support thÃªm CIFAR-10, Fashion-MNIST

## ğŸ“„ License

Code nÃ y dÃ¹ng cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u. Implementation based on LeNet-5 paper (1998) which is in public domain.

## ğŸ™ Acknowledgments

- **Yann LeCun** - LeNet-5 architecture vÃ  MNIST dataset
- **Andrew Ng** - Deep Learning course vá»›i clear explanations
- **Original implementer** - LeNet-from-Scratch notebook structure

---

**Last updated**: November 2025  
**Python version**: 3.6+ (tested on 3.6, 3.9, 3.11)  
**OS**: Windows 10 (should work on Linux/Mac with minor path changes)
